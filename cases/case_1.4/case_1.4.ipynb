{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are returns and volatility related for energy stocks and the broader market?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Context.** You are an analyst at a large bank focused on natural resource stock investments. You recently conducted an analysis of the following energy stocks and how their trading volume is related to their volatility:\n",
    "\n",
    "1. Dominion Energy Inc. (Stock Symbol: D)\n",
    "2. Exelon Corp. (Stock Symbol: EXC)\n",
    "3. NextEra Energy Inc. (Stock Symbol: NEE)\n",
    "4. Southern Co. (Stock Symbol: SO)\n",
    "5. Duke Energy Corp. (Stock Symbol: DUK)\n",
    "\n",
    "Your boss was quite pleased with your previous analysis, and now wants you to conduct additional analysis so he can figure out how to size potential positions in these stocks... i.e. what percentage of the investment portfolio should be dedicated to each of these stocks. Specifically, he wants you to look at daily returns and volatility for each stock as well as for the broader market (i.e. not just the energy sector).\n",
    "\n",
    "This is important because high volatility implies higher risk, and your boss would like to know if the potential returns of these high-volatility energy stocks compensate him for the added risk. Additionally, because his performance is measured or benchmarked against the broader market, he wants to understand whether these stocks generally outperform the broader market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Problem.** Based on the above context, your boss has posed the following question to you: **\"What is the relationship between daily volatility and returns for these stocks, and what is the relationship between daily returns for these stocks and the broader stock market?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analytical Context.** The data you've been given is in the Comma Separated Value (CSV) format, and comprises price and trading volume data for the above stocks. You will proceed by: (1) conducting preliminary cleaning of the data; (2) creating additional features required for our analysis; (3) labelling the data into volatility groups, or regimes, and determining how volatility is related to returns; and finally (4) comparing these returns against those of the broader market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries required for this case\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary cleaning of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can proceed with data analysis and modeling, we first need to determine if the relevant data is adequate to proceed as-is, or if it needs further cleaning. In this case, we have received a Comma Separated Value (CSV) file that includes the following data:\n",
    "\n",
    "1. **Date:** The day of the year\n",
    "2. **Open:** The stock opening price of the day\n",
    "3. **High:** The highest observed stock price of the day\n",
    "4. **Low:** The lowest observed stock price of the day\n",
    "5. **Close:** The stock closing price of the day\n",
    "6. **Adj Close:** The adjusted stock closing price for the day (adjusted for splits and dividends)\n",
    "7. **Volume:** The volume of the stock traded over the day\n",
    "8. **Symbol:** The symbol for that particular stock\n",
    "\n",
    "One very common problem that arises in datasets is missing values. Let's see how to identify whether or not our dataset has this problem, and how to deal with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487   \n",
       "\n",
       "      Volume Symbol  \n",
       "0  1806400.0      D  \n",
       "1  2231100.0      D  \n",
       "2  2588900.0      D  \n",
       "3  3266900.0      D  \n",
       "4  2601800.0      D  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and view head of DataFrame\n",
    "raw_df = pd.read_csv('EnergySectorData.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by determining if we have missing values. We can use the ```pandas``` DataFrame method ```isnull()``` to check for ```NaN``` values in ```raw_df``` (i.e. check for null values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          0\n",
       "Open          2\n",
       "High         14\n",
       "Low           7\n",
       "Close         7\n",
       "Adj Close     7\n",
       "Volume       22\n",
       "Symbol        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are missing values (NaNs)\n",
    "raw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see we have some missing values. Let's instead use the ```mean()``` method to determine what percent of each column we are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0.000000\n",
       "Open         0.000319\n",
       "High         0.002231\n",
       "Low          0.001116\n",
       "Close        0.001116\n",
       "Adj Close    0.001116\n",
       "Volume       0.003506\n",
       "Symbol       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that we are missing less than 0.5% of the observations in any given column. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "We do not want any missing values in our analysis. Which of the following options is the WORST option for how to proceed in this case?\n",
    "\n",
    "(a) Fill in any day's missing value with the previous day's value\n",
    "\n",
    "(b) Replace the missing values by re-gathering the data\n",
    "\n",
    "(c) Estimate the missing values by interpolating them from the values of other, similar data points\n",
    "\n",
    "(d) Remove rows from the dataset that contain missing values\n",
    "\n",
    "**Answer.** (a). We have a couple options that are generally acceptable on how to proceed with missing values:\n",
    "\n",
    "1. One option is to replace the missing values by re-gathering the data. However, this option is often quite expensive in real man-hours, so we will forgo it for now.\n",
    "\n",
    "2. Another option is to try to estimate the missing values using some reasonable estimation method, interpolating from other data points. However, this can be complicated and given that such a little amount of our data is missing, we will forgo this option.\n",
    "\n",
    "3. In practice, a regularly chosen option when only a small amount of data is missing is to just remove the rows that have missing data. This option is generally fine to perform so long as the removed data is an insignificant portion of the data under study. Here we will choose this option as it simplifies the analysis and should not harm any results moving forward.\n",
    "\n",
    "Answer (a) is problematic because replacing a missing value with the previous day's value doesn't make sense for stocks because stock prices and trading volumes are known to move day-to-day rather than remain unchanged for an extended period of time. Since we will be dealing with daily returns and volatility, this is especially problematic as it defaults any missing day's volatility and return to 0.\n",
    "\n",
    "Note that these options for cleaning data should be carefully weighed when commencing a new data science study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the missing values by removing them from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaNs from data\n",
    "# Drop the missing values\n",
    "progress_df = raw_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to be able to analyze these stocks together across time. This would be easier is if all the stocks contained non-missing data for the same set of dates. Let's first ascertain if this is the case. One way to do this is to use the ```groupby``` method to group by ```Date```, then use the ```count()``` function to enumerate how many distinct dates we have. Since there are a total of 1259 rows per symbol, there should be a count of 1259 for each symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUK</th>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXC</th>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEE</th>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Open  High   Low  Close  Adj Close  Volume\n",
       "Symbol                                                  \n",
       "D       1230  1230  1230  1230   1230       1230    1230\n",
       "DUK     1249  1249  1249  1249   1249       1249    1249\n",
       "EXC     1239  1239  1239  1239   1239       1239    1239\n",
       "NEE     1251  1251  1251  1251   1251       1251    1251\n",
       "SO      1259  1259  1259  1259   1259       1259    1259"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many data rows do we have for each Symbol\n",
    "progress_df.groupby('Symbol').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most symbols do not have a count of 1259 for their ```Date``` columns, there are clearly some inconsistent values. Some of these duplicates will be missing values (NaNs), so let's enumerate those again first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          0\n",
       "Open          2\n",
       "High         14\n",
       "Low           7\n",
       "Close         7\n",
       "Adj Close     7\n",
       "Volume       22\n",
       "Symbol        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are missing values (NaNs)\n",
    "raw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, we can remove missing values as there are not many samples that are missing, and dropping a small number of dates is not expected to significantly impact the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing values\n",
    "progress_df = raw_df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUK</th>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXC</th>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "      <td>1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEE</th>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Open  High   Low  Close  Adj Close  Volume\n",
       "Symbol                                                  \n",
       "D       1230  1230  1230  1230   1230       1230    1230\n",
       "DUK     1249  1249  1249  1249   1249       1249    1249\n",
       "EXC     1239  1239  1239  1239   1239       1239    1239\n",
       "NEE     1251  1251  1251  1251   1251       1251    1251\n",
       "SO      1259  1259  1259  1259   1259       1259    1259"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many data rows do we have for each Symbol\n",
    "progress_df.groupby('Symbol').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, we see that different symbols have different numbers of dates. We'd like all the symbols to have the same set of dates for analysis purposes. Let's create a new ```clean_df``` that corresponds to a DataFrame with the same number of rows for each ```Symbol```, where all symbols share the same set of dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_dates_D = set(progress_df[progress_df['Symbol'] == 'D']['Date'])\n",
    "set_dates_EXC = set(progress_df[progress_df['Symbol'] == 'EXC']['Date'])\n",
    "set_dates_NEE = set(progress_df[progress_df['Symbol'] == 'NEE']['Date'])\n",
    "set_dates_SO = set(progress_df[progress_df['Symbol'] == 'SO']['Date'])\n",
    "set_dates_DUK = set(progress_df[progress_df['Symbol'] == 'DUK']['Date'])\n",
    "set_unique_dates = set.intersection(set_dates_D,set_dates_EXC,set_dates_NEE,set_dates_SO,set_dates_DUK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter new DataFrame for only the dates that are present in every symbol (i.e. the overlapping dates)\n",
    "clean_df = progress_df[progress_df['Date'].isin(set_unique_dates)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUK</th>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXC</th>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEE</th>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Open  High   Low  Close  Adj Close  Volume\n",
       "Symbol                                                  \n",
       "D       1192  1192  1192  1192   1192       1192    1192\n",
       "DUK     1192  1192  1192  1192   1192       1192    1192\n",
       "EXC     1192  1192  1192  1192   1192       1192    1192\n",
       "NEE     1192  1192  1192  1192   1192       1192    1192\n",
       "SO      1192  1192  1192  1192   1192       1192    1192"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look\n",
    "clean_df.groupby('Symbol').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that each symbol has the same number of unique dates. Let's write a quick verification program to ensure the resulting ```clean_df``` does indeed have the same dates for every symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "Write code to ensure that each of the symbols share the same set of unique dates. (Hint: use the ```set()``` method.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# One possible solution\n",
    "check_set_dates_D = set(clean_df[clean_df['Symbol'] == 'D']['Date'])\n",
    "check_set_dates_EXC = set(clean_df[clean_df['Symbol'] == 'EXC']['Date'])\n",
    "check_set_dates_NEE = set(clean_df[clean_df['Symbol'] == 'NEE']['Date'])\n",
    "check_set_dates_SO = set(clean_df[clean_df['Symbol'] == 'SO']['Date'])\n",
    "check_set_dates_DUK = set(clean_df[clean_df['Symbol'] == 'DUK']['Date'])\n",
    "\n",
    "print(check_set_dates_D == check_set_dates_EXC)\n",
    "print(check_set_dates_D == check_set_dates_NEE)\n",
    "print(check_set_dates_D == check_set_dates_SO)\n",
    "print(check_set_dates_D == check_set_dates_DUK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've completed the preliminary cleaning of the data, let's move forward with determining the relationships between: (1) stock returns and volatility, and (2) stock returns and broader market returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional variables required for our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the original question requires us to investigate both daily stock returns and the volatility of those returns. This means that important measures of interest are:\n",
    "\n",
    "1. Daily (open to close) stock return\n",
    "2. Volatility of daily stock return\n",
    "\n",
    "Why are each of these important?\n",
    "\n",
    "1. Volatility: Gives insight into amount of price movement in any given day. Volatility is directly related to the level of risk involved in holding the stock.\n",
    "2. Return: Gives us an idea of the return on investment over a period of time.\n",
    "\n",
    "Let's calculate these statistics and add them to the DataFrame ```clean_df```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volume_Millions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>1.8064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>2.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.032286</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>2.5889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>-0.014425</td>\n",
       "      <td>3.2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>2.6018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487   \n",
       "\n",
       "      Volume Symbol   VolStat    Return  Volume_Millions  \n",
       "0  1806400.0      D  0.018781  0.016201           1.8064  \n",
       "1  2231100.0      D  0.014858 -0.010471           2.2311  \n",
       "2  2588900.0      D  0.032286 -0.014714           2.5889  \n",
       "3  3266900.0      D  0.018505 -0.014425           3.2669  \n",
       "4  2601800.0      D  0.017674  0.003861           2.6018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['VolStat'] = (clean_df['High'] - clean_df['Low']) / clean_df['Open']\n",
    "clean_df['Return'] = (clean_df['Close'] / clean_df['Open']) - 1.0\n",
    "clean_df['Volume_Millions'] = clean_df['Volume'] / 1000000.0 # Volume in Millions (added for convenience)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that we've added three columns to ```clean_df```, namely ```VolStat```, ```Return```, and ```Volume_Millions``` (the last one is just for convenience, as the values in the ```Volume``` column are quite large)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are looking to analyze the relationship between daily volatility and returns, an additional column that makes sense to add is one which says ```True``` when the daily return is positive, and ```False``` when the daily return negative. We can then group days into positive and negative return cohorts and compare the average volatility on those days. We will name this column ```ReturnFlag```.\n",
    "\n",
    "We can accomplish this using an **anonymous function**; that is, a function that is defined but not named:\n",
    "```python\n",
    "lambda arguments: expression\n",
    "```\n",
    "\n",
    "The ```lambda``` keyword tells Python that we are using an anonymous function. Next, the ```arguments``` are the name we give to the inputs. It can be ```x```, or ```y```, or whatever the user would like to call it. In this case we will use the name ```row``` for the input argument name as the input will indeed be a row of a DataFrame. The ```expression``` is what is then applied to the ```arguments```; this is the function.\n",
    "\n",
    "Let's take a look at how we can use anonymous functions to create the ```ReturnFlag``` feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volume_Millions</th>\n",
       "      <th>ReturnFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>1.8064</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>2.2311</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.032286</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>2.5889</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>-0.014425</td>\n",
       "      <td>3.2669</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>2.6018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487   \n",
       "\n",
       "      Volume Symbol   VolStat    Return  Volume_Millions  ReturnFlag  \n",
       "0  1806400.0      D  0.018781  0.016201           1.8064        True  \n",
       "1  2231100.0      D  0.014858 -0.010471           2.2311       False  \n",
       "2  2588900.0      D  0.032286 -0.014714           2.5889       False  \n",
       "3  3266900.0      D  0.018505 -0.014425           3.2669       False  \n",
       "4  2601800.0      D  0.017674  0.003861           2.6018        True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['ReturnFlag'] = clean_df.apply(lambda row: True if row['Return'] > 0 else False, axis=1) # Volume in Millions\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the ```apply()``` method takes in an anonymous function and applies it to the rows of the DataFrame through the use of the second argument ```axis```. ```axis=0``` applies the function to columns, whereas ```axis=1``` applies the function to rows.\n",
    "\n",
    "So what is happening in the following statement?\n",
    "```python\n",
    "clean_df['ReturnFlag'] = clean_df.apply(lambda row: True if row['Return] > 0 else False, axis=1)\n",
    "```\n",
    "\n",
    "1. ```pandas``` recogized through the ```apply``` method that it is operating on the ```clean_df``` DataFrame\n",
    "2. The ```apply``` method takes a function as input that will be applied to the DataFrame ```clean_df```\n",
    "3. Given the second argument of ```apply``` is ```axis=1``` the input into the anonymous function is a single row\n",
    "4. For every row, ```row['Return']``` returns the ```Return``` value for that row, and it is subsequently passed through the if statement, returning True if greater than zero and False otherwise\n",
    "5. The new value is stored in the column ```clean_df['ReturnFlag']```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Using ```apply()``` and ```lambda```, write code to create a new column named ```YYYY``` to ```clean_df```, where the new column is the year of the observation as a string. For instance if the row ```Date``` value is 2014-07-28, then the value in the new column for the year would be '2014'. Recall that you can access the first 4 characters of some string ```my_string``` using ```my_string[:4]```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One possible solution\n",
    "clean_df['YYYY'] = clean_df.apply(lambda row: row['Date'][:4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move forward with labelling volatility regimes present in the data â€“ these regimes are useful for breaking down the stock return analysis by periods of low, medium, and high volatility. It will allow for more granular analysis than just looking at overall averages without a breakdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "Using ```apply()``` and ```lambda```, write a script to create a new column in ```clean_df``` named ```AvgDailyPrice``` that calculates an average daily price based on whether or not the daily volume is over 5 million. Set the value of the new column to (Open + High + Low + Close)/4 if the volume is larger than 5 million, or set the value to (High + Low + Close)/3 if the volume is less than or equal to 5 million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volume_Millions</th>\n",
       "      <th>ReturnFlag</th>\n",
       "      <th>YYYY</th>\n",
       "      <th>AvgDailyPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>1.8064</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>70.563332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>2.2311</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>70.280001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.032286</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>2.5889</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>69.343336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>-0.014425</td>\n",
       "      <td>3.2669</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>68.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>2.6018</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>67.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487   \n",
       "\n",
       "      Volume Symbol   VolStat    Return  Volume_Millions  ReturnFlag  YYYY  \\\n",
       "0  1806400.0      D  0.018781  0.016201           1.8064        True  2014   \n",
       "1  2231100.0      D  0.014858 -0.010471           2.2311       False  2014   \n",
       "2  2588900.0      D  0.032286 -0.014714           2.5889       False  2014   \n",
       "3  3266900.0      D  0.018505 -0.014425           3.2669       False  2014   \n",
       "4  2601800.0      D  0.017674  0.003861           2.6018        True  2014   \n",
       "\n",
       "   AvgDailyPrice  \n",
       "0      70.563332  \n",
       "1      70.280001  \n",
       "2      69.343336  \n",
       "3      68.023333  \n",
       "4      67.740000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One possible solution\n",
    "clean_df['AvgDailyPrice'] = clean_df.apply(lambda row:(row['Open']+row['High']+row['Low']+row['Close'])/4 if row['Volume'] > 5000000 else (row['High']+row['Low']+row['Close'])/3, axis=1)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling energy sector volatility regimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Case 1.2, we'd like to label periods of low and high volatilty in a new column called ```VolLevel``` for each Symbol using some lower and upper bound values. For example, in the case of the Symbol D we'd like to have a new column with value determined by:\n",
    "\n",
    "```python\n",
    "if VolStrat > upper_threshold_dict['D']:\n",
    "    VolLevel = '3_HIGH'\n",
    "elif VolStrat < lower_threshold_dict['D']:\n",
    "    VolLevel = '1_LOW'\n",
    "else:\n",
    "    VolLevel = '2_MEDIUM'\n",
    "```\n",
    "\n",
    "Namely, this labelling should be applied to each row, and the threshold values should correspond to the Symbol for that row. We will group by this column and see if we can find any new insights in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 0.010240046986389077,\n",
       " 'DUK': 0.010018315803797114,\n",
       " 'EXC': 0.011881680089172456,\n",
       " 'NEE': 0.010258642787424582,\n",
       " 'SO': 0.009734019893739423}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine lower bounds (we choose to use 25th percentile)\n",
    "lower_threshold_dict = clean_df.groupby('Symbol')['VolStat'].quantile(0.25).to_dict() # 25th percentile bound\n",
    "lower_threshold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 0.017960914526108228,\n",
       " 'DUK': 0.017598380774085175,\n",
       " 'EXC': 0.021801523265676366,\n",
       " 'NEE': 0.017680218024250814,\n",
       " 'SO': 0.016830447068579304}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine upper bounds (we choose to use 75th percentile)\n",
    "upper_threshold_dict = clean_df.groupby('Symbol')['VolStat'].quantile(0.75).to_dict() # 75th percentile bound\n",
    "upper_threshold_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our goal is to label low, medium, and high volatility periods. Let's define a new column called ```VolLevel``` for each Symbol using some lower and upper bound values. Let's define a custom function that will be applied to each row to achieve this goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our custom function, input is a row from the agg_df, and the output is a string, either LOW, MEDIUM, or HIGH\n",
    "def my_custom_row_function(row):\n",
    "    row_symbol = row['Symbol']    # the Symbol value in the row\n",
    "    row_volstat = row['VolStat']  # the VolStat value in the row\n",
    "    \n",
    "    lower_threshold = lower_threshold_dict[row_symbol] # Dictionary of {string:float}\n",
    "    upper_threshold = upper_threshold_dict[row_symbol] # Dictionary of {string:float}\n",
    "    \n",
    "    # The function decision, return value depending on low, medium, or high volatility\n",
    "    if row_volstat > upper_threshold:\n",
    "        return '3_HIGH'\n",
    "    elif row_volstat < lower_threshold:\n",
    "        return '1_LOW'\n",
    "    else:\n",
    "        return '2_MEDIUM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply the function to each row of the DataFrame ```clean_df``` using a ```lambda``` statement. We store the returned values in the new column ```VolLevel```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volume_Millions</th>\n",
       "      <th>ReturnFlag</th>\n",
       "      <th>YYYY</th>\n",
       "      <th>AvgDailyPrice</th>\n",
       "      <th>VolLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-28</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>71.059998</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>70.879997</td>\n",
       "      <td>57.963978</td>\n",
       "      <td>1806400.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>1.8064</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>70.563332</td>\n",
       "      <td>3_HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>70.669998</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>69.930000</td>\n",
       "      <td>57.187099</td>\n",
       "      <td>2231100.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>2.2311</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>70.280001</td>\n",
       "      <td>2_MEDIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.660004</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>56.402020</td>\n",
       "      <td>2588900.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.032286</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>2.5889</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>69.343336</td>\n",
       "      <td>3_HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>68.849998</td>\n",
       "      <td>67.580002</td>\n",
       "      <td>67.639999</td>\n",
       "      <td>55.314388</td>\n",
       "      <td>3266900.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>-0.014425</td>\n",
       "      <td>3.2669</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>68.023333</td>\n",
       "      <td>3_HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>67.330002</td>\n",
       "      <td>68.410004</td>\n",
       "      <td>67.220001</td>\n",
       "      <td>67.589996</td>\n",
       "      <td>55.273487</td>\n",
       "      <td>2601800.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.017674</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>2.6018</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "      <td>67.740000</td>\n",
       "      <td>2_MEDIUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978   \n",
       "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099   \n",
       "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020   \n",
       "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388   \n",
       "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487   \n",
       "\n",
       "      Volume Symbol   VolStat    Return  Volume_Millions  ReturnFlag  YYYY  \\\n",
       "0  1806400.0      D  0.018781  0.016201           1.8064        True  2014   \n",
       "1  2231100.0      D  0.014858 -0.010471           2.2311       False  2014   \n",
       "2  2588900.0      D  0.032286 -0.014714           2.5889       False  2014   \n",
       "3  3266900.0      D  0.018505 -0.014425           3.2669       False  2014   \n",
       "4  2601800.0      D  0.017674  0.003861           2.6018        True  2014   \n",
       "\n",
       "   AvgDailyPrice  VolLevel  \n",
       "0      70.563332    3_HIGH  \n",
       "1      70.280001  2_MEDIUM  \n",
       "2      69.343336    3_HIGH  \n",
       "3      68.023333    3_HIGH  \n",
       "4      67.740000  2_MEDIUM  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply my_custom_row_function to the Pandas DataFrame, row by row (axis=1)\n",
    "clean_df['VolLevel'] = clean_df.apply(lambda row: my_custom_row_function(row), axis=1)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the workflow here may seem complex at first, the ability to apply custom functions, group by certain features, and construct summary statistics will prove invaluable as you progress onto more advanced analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "\n",
    "Using ```clean_df``` and a ```lambda``` statement within ```apply()```, write a function ```new_custom_function()``` and a script to add a new column to the DataFrame (call it ```EnhancedVolLevel```) that operates in a similar manner as VolLevel but instead gives five volatility level categories using the following logic to determine the label for the volatility level:\n",
    "\n",
    "```python\n",
    "if VolStrat > 90th percentile:\n",
    "    VolLevel = '5_VERY_HIGH'\n",
    "elif VolStrat > 75th percentile:\n",
    "    VolLevel = '4_HIGH'\n",
    "elif VolStrat > 25th percentile:\n",
    "    VolLevel = '3_MEDIUM'\n",
    "elif VolStrat > 10th percentile:\n",
    "    VolLevel = '2_LOW'\n",
    "else:\n",
    "    VolLevel = '1_VERY_LOW'\n",
    "```\n",
    "\n",
    "Remember each percentile should be calculated by symbol. Use these new labels to see if there are any patterns between volatility levels and the direction of returns. Produce the DataFrame to be able to run the following command:\n",
    "\n",
    "```python\n",
    "clean_df.groupby(['Symbol','EnhancedVolLevel'])['ReturnFlag'].mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       Open       High        Low      Close  Adj Close  \\\n",
      "0  2014-07-28  69.750000  71.059998  69.750000  70.879997  57.963978   \n",
      "1  2014-07-29  70.669998  70.980003  69.930000  69.930000  57.187099   \n",
      "2  2014-07-30  70.000000  70.660004  68.400002  68.970001  56.402020   \n",
      "3  2014-07-31  68.629997  68.849998  67.580002  67.639999  55.314388   \n",
      "4  2014-08-01  67.330002  68.410004  67.220001  67.589996  55.273487   \n",
      "\n",
      "      Volume Symbol   VolStat    Return  Volume_Millions  ReturnFlag  YYYY  \\\n",
      "0  1806400.0      D  0.018781  0.016201           1.8064        True  2014   \n",
      "1  2231100.0      D  0.014858 -0.010471           2.2311       False  2014   \n",
      "2  2588900.0      D  0.032286 -0.014714           2.5889       False  2014   \n",
      "3  3266900.0      D  0.018505 -0.014425           3.2669       False  2014   \n",
      "4  2601800.0      D  0.017674  0.003861           2.6018        True  2014   \n",
      "\n",
      "   AvgDailyPrice  VolLevel EnhancedVolLevel  \n",
      "0      70.563332    3_HIGH           4_HIGH  \n",
      "1      70.280001  2_MEDIUM         3_MEDIUM  \n",
      "2      69.343336    3_HIGH      5_VERY_HIGH  \n",
      "3      68.023333    3_HIGH           4_HIGH  \n",
      "4      67.740000  2_MEDIUM         3_MEDIUM  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Symbol  EnhancedVolLevel\n",
       "D       1_VERY_LOW          0.508333\n",
       "        2_LOW               0.573034\n",
       "        3_MEDIUM            0.558725\n",
       "        4_HIGH              0.528090\n",
       "        5_VERY_HIGH         0.408333\n",
       "DUK     1_VERY_LOW          0.550000\n",
       "        2_LOW               0.522472\n",
       "        3_MEDIUM            0.558725\n",
       "        4_HIGH              0.511236\n",
       "        5_VERY_HIGH         0.433333\n",
       "EXC     1_VERY_LOW          0.533333\n",
       "        2_LOW               0.533708\n",
       "        3_MEDIUM            0.508389\n",
       "        4_HIGH              0.533708\n",
       "        5_VERY_HIGH         0.500000\n",
       "NEE     1_VERY_LOW          0.566667\n",
       "        2_LOW               0.550562\n",
       "        3_MEDIUM            0.567114\n",
       "        4_HIGH              0.522472\n",
       "        5_VERY_HIGH         0.500000\n",
       "SO      1_VERY_LOW          0.516667\n",
       "        2_LOW               0.511236\n",
       "        3_MEDIUM            0.530201\n",
       "        4_HIGH              0.500000\n",
       "        5_VERY_HIGH         0.516667\n",
       "Name: ReturnFlag, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One possible solution\n",
    "def new_custom_function(row):\n",
    "    row_symbol = row['Symbol']    # the Symbol value in the row\n",
    "    row_volstat = row['VolStat']  # the VolStat value in the row\n",
    "    \n",
    "    very_lower_threshold = very_lower_threshold_dict[row_symbol] # Dictionary of {string:float}\n",
    "    lower_threshold = lower_threshold_dict[row_symbol] # Dictionary of {string:float}\n",
    "    upper_threshold = upper_threshold_dict[row_symbol] # Dictionary of {string:float}\n",
    "    very_upper_threshold = very_upper_threshold_dict[row_symbol] # Dictionary of {string:float}\n",
    "    \n",
    "    # The function decision, return value depending on very low, low, medium, high, or very high volatility\n",
    "    if row_volstat > very_upper_threshold:\n",
    "        return '5_VERY_HIGH'\n",
    "    elif row_volstat > upper_threshold:\n",
    "        return '4_HIGH'\n",
    "    elif row_volstat > lower_threshold:\n",
    "        return '3_MEDIUM'\n",
    "    elif row_volstat > very_lower_threshold:\n",
    "        return '2_LOW'\n",
    "    else:\n",
    "        return '1_VERY_LOW'\n",
    "    \n",
    "# Find thresholds\n",
    "very_upper_threshold_dict = clean_df.groupby('Symbol')['VolStat'].quantile(0.90).to_dict() # 90th percentile bound\n",
    "upper_threshold_dict = clean_df.groupby('Symbol')['VolStat'].quantile(0.75).to_dict() # 75th percentile bound\n",
    "lower_threshold_dict = clean_df.groupby('Symbol')['VolStat'].quantile(0.25).to_dict() # 25th percentile bound\n",
    "very_lower_threshold_dict = clean_df.groupby('Symbol')['VolStat'].quantile(0.10).to_dict() # 10th percentile bound\n",
    "\n",
    "# Calculate and add new column\n",
    "clean_df['EnhancedVolLevel'] = clean_df.apply(lambda row: new_custom_function(row), axis=1)\n",
    "print(clean_df.head())\n",
    "\n",
    "# Result\n",
    "clean_df.groupby(['Symbol','EnhancedVolLevel'])['ReturnFlag'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that volatility and stock returns do not exhibit any strong patterns in terms of the average return direction (positive or negative) for a given volatility regime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing stock returns to broader market returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look into the second part of your boss's question: what is the relationship between broader market returns and the returns of these five energy stocks? The S&P 500 Index is a stock index comprised of about 500 large-capitalization public US companies. The index is often used as a representation of the US stock market. If we can determine whether or not there exists a strong relationship between these 5 energy stocks' returns and those of the S&P 500 Index, we can determine if there are signficant idiosyncratic characteristics at play among the energy sector stock returns, or if the returns are solely driven by the broader market.\n",
    "\n",
    "Market returns for the tradable S&P 500 index ETF (exchange-traded fund) are available in ```SPY.csv``` (the \"stock\" symbol of the ETF is SPY). Let's load the data and append the daily returns onto the cleaned energy sector data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file into DataFrame\n",
    "market_df = pd.read_csv('SPY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Return</th>\n",
       "      <th>VolStat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>196.800003</td>\n",
       "      <td>197.449997</td>\n",
       "      <td>196.690002</td>\n",
       "      <td>197.360001</td>\n",
       "      <td>178.729111</td>\n",
       "      <td>75424000</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.003862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-19</td>\n",
       "      <td>197.839996</td>\n",
       "      <td>198.539993</td>\n",
       "      <td>197.440002</td>\n",
       "      <td>198.389999</td>\n",
       "      <td>179.661896</td>\n",
       "      <td>59135000</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.005560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>198.119995</td>\n",
       "      <td>199.160004</td>\n",
       "      <td>198.080002</td>\n",
       "      <td>198.919998</td>\n",
       "      <td>180.141846</td>\n",
       "      <td>72763000</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.005451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>199.089996</td>\n",
       "      <td>199.759995</td>\n",
       "      <td>198.929993</td>\n",
       "      <td>199.500000</td>\n",
       "      <td>180.667160</td>\n",
       "      <td>67791000</td>\n",
       "      <td>SPY</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.004169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-22</td>\n",
       "      <td>199.339996</td>\n",
       "      <td>199.690002</td>\n",
       "      <td>198.740005</td>\n",
       "      <td>199.190002</td>\n",
       "      <td>180.386368</td>\n",
       "      <td>76107000</td>\n",
       "      <td>SPY</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>0.004766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2014-08-18  196.800003  197.449997  196.690002  197.360001  178.729111   \n",
       "1  2014-08-19  197.839996  198.539993  197.440002  198.389999  179.661896   \n",
       "2  2014-08-20  198.119995  199.160004  198.080002  198.919998  180.141846   \n",
       "3  2014-08-21  199.089996  199.759995  198.929993  199.500000  180.667160   \n",
       "4  2014-08-22  199.339996  199.690002  198.740005  199.190002  180.386368   \n",
       "\n",
       "     Volume Symbol    Return   VolStat  \n",
       "0  75424000    SPY  0.002846  0.003862  \n",
       "1  59135000    SPY  0.002780  0.005560  \n",
       "2  72763000    SPY  0.004038  0.005451  \n",
       "3  67791000    SPY  0.002059  0.004169  \n",
       "4  76107000    SPY -0.000752  0.004766  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_df['Symbol'] = 'SPY' # add column for symbol\n",
    "market_df['Return'] = (market_df['Close'] / market_df['Open']) - 1.0 # calculate return\n",
    "market_df['VolStat'] = (market_df['High'] - market_df['Low']) / market_df['Open']\n",
    "market_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to merge the market returns in ```market_df``` and the energy stock data in ```clean_df```.  This can be accomplished using ```pd.merge()``` - a versatile method to join together DataFrames.\n",
    "\n",
    "For those of you familiar with SQL, merging and joining DataFrames can be accomplished in much the same way that SQL accomplishes these tasks (if you are not familiar with SQL, don't worry â€“ we will cover it in later cases). In this case, we'd like to use the intersection of dates in ```clean_df``` and ```market_df``` dates as the indices in the merge (i.e. in SQL parlance, we will perform an ```inner``` merge):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge inner (merge market_df onto clean_df using the dates of clean_df as the keys)\n",
    "merged_df = pd.merge(clean_df, market_df[['Date','Return']], how='inner', on='Date', suffixes=('','_SPY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol\n",
       "D      1178\n",
       "DUK    1178\n",
       "EXC    1178\n",
       "NEE    1178\n",
       "SO     1178\n",
       "Name: Date, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many dates are in the intersection\n",
    "merged_df.groupby('Symbol')['Date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>VolStat</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volume_Millions</th>\n",
       "      <th>ReturnFlag</th>\n",
       "      <th>YYYY</th>\n",
       "      <th>AvgDailyPrice</th>\n",
       "      <th>VolLevel</th>\n",
       "      <th>EnhancedVolLevel</th>\n",
       "      <th>Return_SPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>68.970001</td>\n",
       "      <td>69.250000</td>\n",
       "      <td>68.559998</td>\n",
       "      <td>68.680000</td>\n",
       "      <td>56.164867</td>\n",
       "      <td>1375600.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>1.3756</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>68.829999</td>\n",
       "      <td>1_LOW</td>\n",
       "      <td>2_LOW</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>31.930000</td>\n",
       "      <td>32.099998</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.820000</td>\n",
       "      <td>26.593485</td>\n",
       "      <td>4037400.0</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.011588</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>4.0374</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>31.883333</td>\n",
       "      <td>1_LOW</td>\n",
       "      <td>2_LOW</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>96.589996</td>\n",
       "      <td>97.180000</td>\n",
       "      <td>95.889999</td>\n",
       "      <td>96.139999</td>\n",
       "      <td>82.166077</td>\n",
       "      <td>1098200.0</td>\n",
       "      <td>NEE</td>\n",
       "      <td>0.013355</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>1.0982</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>96.403333</td>\n",
       "      <td>2_MEDIUM</td>\n",
       "      <td>3_MEDIUM</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>43.529999</td>\n",
       "      <td>43.720001</td>\n",
       "      <td>43.279999</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>34.210857</td>\n",
       "      <td>2979800.0</td>\n",
       "      <td>SO</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>-0.003446</td>\n",
       "      <td>2.9798</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>43.460000</td>\n",
       "      <td>2_MEDIUM</td>\n",
       "      <td>3_MEDIUM</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>72.300003</td>\n",
       "      <td>72.650002</td>\n",
       "      <td>71.919998</td>\n",
       "      <td>72.089996</td>\n",
       "      <td>58.080738</td>\n",
       "      <td>1826000.0</td>\n",
       "      <td>DUK</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>1.8260</td>\n",
       "      <td>False</td>\n",
       "      <td>2014</td>\n",
       "      <td>72.219999</td>\n",
       "      <td>2_MEDIUM</td>\n",
       "      <td>3_MEDIUM</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2014-08-18  68.970001  69.250000  68.559998  68.680000  56.164867   \n",
       "1  2014-08-18  31.930000  32.099998  31.730000  31.820000  26.593485   \n",
       "2  2014-08-18  96.589996  97.180000  95.889999  96.139999  82.166077   \n",
       "3  2014-08-18  43.529999  43.720001  43.279999  43.380001  34.210857   \n",
       "4  2014-08-18  72.300003  72.650002  71.919998  72.089996  58.080738   \n",
       "\n",
       "      Volume Symbol   VolStat    Return  Volume_Millions  ReturnFlag  YYYY  \\\n",
       "0  1375600.0      D  0.010004 -0.004205           1.3756       False  2014   \n",
       "1  4037400.0    EXC  0.011588 -0.003445           4.0374       False  2014   \n",
       "2  1098200.0    NEE  0.013355 -0.004659           1.0982       False  2014   \n",
       "3  2979800.0     SO  0.010108 -0.003446           2.9798       False  2014   \n",
       "4  1826000.0    DUK  0.010097 -0.002905           1.8260       False  2014   \n",
       "\n",
       "   AvgDailyPrice  VolLevel EnhancedVolLevel  Return_SPY  \n",
       "0      68.829999     1_LOW            2_LOW    0.002846  \n",
       "1      31.883333     1_LOW            2_LOW    0.002846  \n",
       "2      96.403333  2_MEDIUM         3_MEDIUM    0.002846  \n",
       "3      43.460000  2_MEDIUM         3_MEDIUM    0.002846  \n",
       "4      72.219999  2_MEDIUM         3_MEDIUM    0.002846  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "\n",
    "Using only Symbol D in ```clean_df``` and ```market_df```, use ```pd.merge()``` to determine how many dates are in ```clean_df``` that are not in ```market_df```. Additionally, how many dates are in ```market_df``` that are not in ```clean_df```? (Hint: isnull() may be useful to simplify the solution.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- outer merge HEAD ---\n",
      "         Date    Return  Return_SPY\n",
      "0  2014-07-28  0.016201         NaN\n",
      "1  2014-07-29 -0.010471         NaN\n",
      "2  2014-07-30 -0.014714         NaN\n",
      "3  2014-07-31 -0.014425         NaN\n",
      "4  2014-08-01  0.003861         NaN\n",
      "--- outer merge TAIL ---\n",
      "            Date  Return  Return_SPY\n",
      "1268  2019-08-12     NaN   -0.006518\n",
      "1269  2019-08-13     NaN    0.016716\n",
      "1270  2019-08-14     NaN   -0.014476\n",
      "1271  2019-08-15     NaN   -0.000807\n",
      "1272  2019-08-16     NaN    0.008273\n",
      "--- outer merge NaN count ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Return        81\n",
       "Return_SPY    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One possible solution\n",
    "\n",
    "outer_df = pd.merge(clean_df[clean_df['Symbol'] == 'D'][['Date','Return']], market_df[['Date','Return']], how='outer', on='Date', suffixes=('','_SPY'))\n",
    "print('--- outer merge HEAD ---')\n",
    "print(outer_df.head())\n",
    "print('--- outer merge TAIL ---')\n",
    "print(outer_df.tail())\n",
    "print('--- outer merge NaN count ---')\n",
    "outer_df.isnull().sum()\n",
    "\n",
    "# Answer to: For Symbol D, how many dates are in clean_df that are not in market_df? -> 14\n",
    "# Answer to: For Symbol D, how many dates are in market_df that are not in clean_df? -> 81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7:\n",
    "\n",
    "Use ```market_df``` and ```clean_df``` to create a new DataFrame ```modified_clean_df``` that is the same as ```clean_df``` but with a new column named ```MeanMonthSPYReturn```. Each value in the new column should be the mean monthly return for SPY for the given month of each row's ```Date```. The output for the first and last rows of the ```modified_clean_df``` DataFrame should produce the following output from head(1) and tail(1):\n",
    "```python\n",
    "print(modified_clean_df[['Date','Symbol','YYYYMM','MeanMonthSPYReturn']].head(1))\n",
    "```\n",
    "\n",
    "                 Date       Symbol YYYYMM MeanMonthSPYReturn\n",
    "                 2014-08-01 D      201408 0.001443\n",
    "\n",
    "```python\n",
    "print(modified_clean_df[['Date','Symbol','YYYYMM','MeanMonthSPYReturn']].tail(1))\n",
    "```\n",
    "                 Date       Symbol YYYYMM MeanMonthSPYReturn\n",
    "                 2019-07-26 DUK    201907 0.000167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Symbol  YYYYMM  MeanMonthSPYReturn\n",
      "0  2014-08-01      D  201408            0.001443\n",
      "            Date Symbol  YYYYMM  MeanMonthSPYReturn\n",
      "5939  2019-07-26    DUK  201907            0.000167\n"
     ]
    }
   ],
   "source": [
    "# One possible solution\n",
    "# Add YYYYMM to market_df and clean_df\n",
    "market_df['YYYYMM'] = market_df.apply(lambda row: row['Date'][:4] + row['Date'][5:7], axis=1)\n",
    "clean_df['YYYYMM'] = clean_df.apply(lambda row: row['Date'][:4] + row['Date'][5:7], axis=1)\n",
    "\n",
    "# Calculate modified_market_df DataFrame for SPY\n",
    "modified_market_df = market_df.groupby(['Symbol','YYYYMM']).mean().reset_index()\n",
    "modified_market_df = modified_market_df.rename(columns={'Return':'MeanMonthSPYReturn'}) # rename column\n",
    "\n",
    "# Inner merge modified_market_df DataFrame and clean_df by YYYYMM\n",
    "modified_clean_df = pd.merge(clean_df, modified_market_df[['YYYYMM','MeanMonthSPYReturn']], how='inner', on='YYYYMM')\n",
    "\n",
    "# Print results\n",
    "print(modified_clean_df[['Date','Symbol','YYYYMM','MeanMonthSPYReturn']].head(1))\n",
    "print(modified_clean_df[['Date','Symbol','YYYYMM','MeanMonthSPYReturn']].tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking down returns based on the broader market return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can begin our granular analysis of how broader market returns are related to single stock returns. \n",
    "\n",
    "Let's begin by breaking down broader market returns into quantiles. This quantile analysis approach we will take is commonly employed in data analysis to determine how the magnitude of one variable is related to another variable of interest.\n",
    "\n",
    "We can explore this idea with the ```pd.qcut()``` method. Namely, ```pd.qcut()``` will allow us to cut the market returns by quantiles (we will eventually group by quantiles), and therefore will allow us to calculate summary statistics (such as average return) for each quantile.\n",
    "\n",
    "Let's first extract the returns using the convenience of the ```pivot()``` method on a DataFrame. Pivoting a DataFrame may be accomplished by specifying:\n",
    "\n",
    "1. An index to pivot on. In this case we choose ```Date```.\n",
    "2. Columns that we'd like to have after the pivot. In this case we'd like columns that are the ````Symbol```.\n",
    "3. The values that each (row,column) pair will show. In this case we'd like to have the ```Return```.\n",
    "\n",
    "We will pivot ```merged_df``` using these parameter inputs to output a DataFrame where the rows are the Date, each column is the Symbol, and the values are the open-to-close daily return for the given date and symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Symbol</th>\n",
       "      <th>D</th>\n",
       "      <th>DUK</th>\n",
       "      <th>EXC</th>\n",
       "      <th>NEE</th>\n",
       "      <th>SO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-08-18</th>\n",
       "      <td>-0.004205</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>-0.003446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-19</th>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.009838</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-20</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-21</th>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-22</th>\n",
       "      <td>-0.004297</td>\n",
       "      <td>-0.008302</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>-0.003470</td>\n",
       "      <td>-0.003195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Symbol             D       DUK       EXC       NEE        SO\n",
       "Date                                                        \n",
       "2014-08-18 -0.004205 -0.002905 -0.003445 -0.004659 -0.003446\n",
       "2014-08-19  0.013250  0.009838  0.001567  0.008393  0.005741\n",
       "2014-08-20  0.001438  0.002480  0.000313  0.005349  0.005508\n",
       "2014-08-21  0.000718  0.003159  0.010022  0.002147  0.000000\n",
       "2014-08-22 -0.004297 -0.008302  0.006213 -0.003470 -0.003195"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract returns from merged_df, where we use pivot to simplify the task\n",
    "return_df = merged_df.pivot(index='Date', columns='Symbol', values='Return')\n",
    "return_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge on the broader market returns from the SPY ```market_df``` loaded earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>D</th>\n",
       "      <th>DUK</th>\n",
       "      <th>EXC</th>\n",
       "      <th>NEE</th>\n",
       "      <th>SO</th>\n",
       "      <th>MarketReturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>-0.003446</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-19</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.009838</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.002780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.004038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-22</td>\n",
       "      <td>-0.004297</td>\n",
       "      <td>-0.008302</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>-0.003470</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.000752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         D       DUK       EXC       NEE        SO  MarketReturn\n",
       "0  2014-08-18 -0.004205 -0.002905 -0.003445 -0.004659 -0.003446      0.002846\n",
       "1  2014-08-19  0.013250  0.009838  0.001567  0.008393  0.005741      0.002780\n",
       "2  2014-08-20  0.001438  0.002480  0.000313  0.005349  0.005508      0.004038\n",
       "3  2014-08-21  0.000718  0.003159  0.010022  0.002147  0.000000      0.002059\n",
       "4  2014-08-22 -0.004297 -0.008302  0.006213 -0.003470 -0.003195     -0.000752"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's merge the SPY (broader market) returns by Date onto the return_df DataFrame\n",
    "full_df = pd.merge(return_df, market_df[['Date','Return']].set_index('Date'), left_index=True, right_index=True)\n",
    "full_df = full_df.rename(columns={'Return':'MarketReturn'}).reset_index()\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through a few simple lines we've created a DataFrame ```full_df``` where each value is an open-to-close daily return, whether it be for one of the five symbols under study, or for the broader market.\n",
    "\n",
    "We proceed by utilizing ```pd.qcut()``` with 10 quantiles. In general, the number of quantiles should be chosen based on how granular of a view you require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>D</th>\n",
       "      <th>DUK</th>\n",
       "      <th>EXC</th>\n",
       "      <th>NEE</th>\n",
       "      <th>SO</th>\n",
       "      <th>MarketReturn</th>\n",
       "      <th>market_quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>-0.003446</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-19</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.009838</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-22</td>\n",
       "      <td>-0.004297</td>\n",
       "      <td>-0.008302</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>-0.003470</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         D       DUK       EXC       NEE        SO  MarketReturn  \\\n",
       "0  2014-08-18 -0.004205 -0.002905 -0.003445 -0.004659 -0.003446      0.002846   \n",
       "1  2014-08-19  0.013250  0.009838  0.001567  0.008393  0.005741      0.002780   \n",
       "2  2014-08-20  0.001438  0.002480  0.000313  0.005349  0.005508      0.004038   \n",
       "3  2014-08-21  0.000718  0.003159  0.010022  0.002147  0.000000      0.002059   \n",
       "4  2014-08-22 -0.004297 -0.008302  0.006213 -0.003470 -0.003195     -0.000752   \n",
       "\n",
       "   market_quantile  \n",
       "0                7  \n",
       "1                7  \n",
       "2                7  \n",
       "3                6  \n",
       "4                3  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 10 quantile categories by the market return\n",
    "num_quantiles = 10\n",
    "full_df['market_quantile'] = pd.qcut(full_df['MarketReturn'],num_quantiles,labels=False)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's group by ```market_quantile``` and calculate the mean return for all the symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>DUK</th>\n",
       "      <th>EXC</th>\n",
       "      <th>NEE</th>\n",
       "      <th>SO</th>\n",
       "      <th>MarketReturn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_quantile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004553</td>\n",
       "      <td>-0.003282</td>\n",
       "      <td>-0.006711</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>-0.002890</td>\n",
       "      <td>-0.013363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002423</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>-0.000830</td>\n",
       "      <td>-0.005045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001612</td>\n",
       "      <td>-0.000617</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>-0.000693</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>-0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>-0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>-0.001240</td>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.002055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.003568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.005787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.012087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        D       DUK       EXC       NEE        SO  \\\n",
       "market_quantile                                                     \n",
       "0               -0.004553 -0.003282 -0.006711 -0.004723 -0.002890   \n",
       "1               -0.002423 -0.001444 -0.002686 -0.001001 -0.000830   \n",
       "2               -0.001612 -0.000617 -0.001087 -0.000693 -0.000061   \n",
       "3                0.001010  0.000420 -0.001277  0.000728  0.000938   \n",
       "4                0.001189  0.000615  0.000377  0.000903  0.000444   \n",
       "5               -0.001516 -0.001656 -0.000699 -0.000985 -0.001240   \n",
       "6                0.001950  0.001233  0.002246  0.002210  0.001040   \n",
       "7                0.001804  0.000505  0.001006  0.000831  0.000963   \n",
       "8                0.002148  0.002366  0.004323  0.003042  0.002563   \n",
       "9                0.005446  0.004366  0.007506  0.006591  0.004721   \n",
       "\n",
       "                 MarketReturn  \n",
       "market_quantile                \n",
       "0                   -0.013363  \n",
       "1                   -0.005045  \n",
       "2                   -0.002577  \n",
       "3                   -0.001154  \n",
       "4                   -0.000113  \n",
       "5                    0.000887  \n",
       "6                    0.002055  \n",
       "7                    0.003568  \n",
       "8                    0.005787  \n",
       "9                    0.012087  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by market quantile and calculate the mean return\n",
    "full_df.groupby('market_quantile').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each value in the above DataFrame output is a mean of daily returns for a given symbol, where the mean is taken across all dates that correspond to the ```market_quantile``` listed as the index of the output DataFrame. Note that higher quantile numbers indicate higher market returns, while lower quantile numbers indicate lower market returns (in this case, negative market returns).\n",
    "\n",
    "We see here that the energy stock returns do indeed follow a pattern when the SPY returns are large (higher quantile number) or small (lower quantile number). Namely, stock returns of the individual stocks follow the same pattern as those of the broader market. Hence, the broader market has an effect on the single-stock returns; that is, the magnitude of the broader stock market return is correlated with the magnitude of the return of the individual stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8:\n",
    "\n",
    "We created quantiles for market returns and subsequently calculated the mean return for each of these quantiles. Perform a similar analysis as above, but instead group by quantiles for the market volatility rather than market returns, and calculate the standard deviation of returns for each market volatility quantile category rather than the mean return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>DUK</th>\n",
       "      <th>EXC</th>\n",
       "      <th>NEE</th>\n",
       "      <th>SO</th>\n",
       "      <th>MarketVolStat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_volstat_quantile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.010409</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>0.008751</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009557</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.011419</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.001292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014097</td>\n",
       "      <td>0.013590</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.014441</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.009016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                D       DUK       EXC       NEE        SO  \\\n",
       "market_volstat_quantile                                                     \n",
       "0                        0.007394  0.007464  0.009186  0.007310  0.008521   \n",
       "1                        0.007177  0.007135  0.009354  0.007658  0.006974   \n",
       "2                        0.008480  0.008084  0.009745  0.007748  0.007407   \n",
       "3                        0.008298  0.008194  0.010211  0.008106  0.007824   \n",
       "4                        0.009563  0.008093  0.010409  0.007003  0.008374   \n",
       "5                        0.009868  0.008642  0.010350  0.008032  0.008836   \n",
       "6                        0.008900  0.009298  0.013011  0.008751  0.009049   \n",
       "7                        0.009557  0.009409  0.010587  0.010960  0.008547   \n",
       "8                        0.010907  0.011419  0.013512  0.010837  0.010354   \n",
       "9                        0.014097  0.013590  0.016814  0.014441  0.012464   \n",
       "\n",
       "                         MarketVolStat  \n",
       "market_volstat_quantile                 \n",
       "0                             0.000508  \n",
       "1                             0.000262  \n",
       "2                             0.000242  \n",
       "3                             0.000245  \n",
       "4                             0.000301  \n",
       "5                             0.000370  \n",
       "6                             0.000509  \n",
       "7                             0.000674  \n",
       "8                             0.001292  \n",
       "9                             0.009016  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One possible solution\n",
    "# Merge market volstat onto returns\n",
    "new_df = pd.merge(return_df, market_df[['Date','VolStat']].set_index('Date'), left_index=True, right_index=True)\n",
    "new_df = new_df.rename(columns={'VolStat':'MarketVolStat'}).reset_index()\n",
    "\n",
    "# Add on quantiles\n",
    "num_quantiles = 10\n",
    "new_df['market_volstat_quantile'] = pd.qcut(new_df['MarketVolStat'],num_quantiles,labels=False)\n",
    "\n",
    "# Calcualte mean by quantile\n",
    "new_df.groupby('market_volstat_quantile').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to how stock returns' directions follow those of the broader market, the volatility of stock returns also follow the volatility of returns of the broader market. This warrants further analysis of the root cause of this effect as a future project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've explored stock returns for the five energy sector stocks in terms of their own volatility regimes, and their returns and volatility relative to the broader market. We found that for the stocks under study, there is no strong link between volatility level and the direction of the daily stock return. Moreover, we found that when comparing stocks to the broader market, their returns and volatility levels are amplified when the market returns and volatility levels are high. These findings indicate there is an intrinsic link between returns and volatility, both in the single stock case and the broader market case. This lends a variety of avenues of exploration for follow-up projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you learned multiple data manipulation tools in ```pandas```, including anonymous functions, grouping, merging, quantile cuttting, and pivoting, while making use of data transformation and aggegation analysis techniques that we've previously learned.\n",
    "\n",
    "```pandas``` is an increbily versatile package and can significantly increase productivity and deliver exceptional business insights. These techniques should serve as a strong basis for any future data analyses you may conduct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
